# 机器学习

## 机器学习分类

### 1.监督学习

监督学习（Supervised Learning）是**从有标签的训练数据中学习模型**，**然后对某个给定的新数据利用模型预测它的标签**。如果分类标签精确度越高，则学习模型准确度越高，预测结果越精确。

监督学习主要用于**回归**和**分类**。

常见的监督学习的**回归算法有线性回归、回归树、K邻近、Adaboost、神经网络等。**

常见的监督学习的**分类算法有朴素贝叶斯、决策树、SVM、逻辑回归、K邻近、Adaboost、神经网络等。**

### 2.半监督学习

半监督学习（Semi-Supervised Learning）是**利用少量标注数据和大量无标注数据进行学习的模式。**

半监督学习**侧重于在有监督的分类算法中加入无标记样本来实现半监督分类。**

常见的半监督学习算法有Pseudo-Label、Π-Model、Temporal Ensembling、Mean Teacher、VAT、UDA、MixMatch、ReMixMatch、FixMatch等。

### 3.无监督学习

无监督学习（Unsupervised Learning）是**从未标注数据中寻找隐含结构的过程。**

无监督学习**主要用于关联分析、聚类和降维。**

常见的无监督学习算法有稀疏自编码（Sparse Auto-Encoder）、主成分分析（Principal Component Analysis, PCA）、K-Means算法（K均值算法）、DBSCAN算法（Density-Based Spatial Clustering of Applications with Noise）、最大期望算法（Expectation-Maximization algorithm, EM）等。

### 4.强化学习

强化学习（Reinforcement Learning）**类似于监督学习，但未使用样本数据进行训练，是是通过不断试错进行学习的模式。**

在强化学习中，有两个可以进行交互的对象：智能体（Agnet）和环境（Environment），还有四个核心要素：策略（Policy）、回报函数（收益信号，Reward Function）、价值函数（Value Function）和环境模型（Environment Model），其中环境模型是可选的。

## 机器学习应用场合

### 1.自然语言处理（NLP）

自然语言处理是人工智能中的重要领域之一，涉及计算机与人类自然语言的交互。NLP技术可以实现语音识别、文本分析、情感分析等任务，为智能客服、聊天机器人、语音助手等提供支持。

### 2.医疗诊断与影像分析

机器学习在医疗领域有着广泛的应用，包括医疗图像分析、疾病预测、药物发现等。深度学习模型在医疗影像诊断中的表现引人注目。

### 3.金融风险管理

机器学习在金融领域的应用越来越重要，尤其是在风险管理方面。模型可以分析大量的金融数据，预测市场波动性、信用风险等。

### 4.预测与推荐系统

机器学习在预测和推荐系统中也有广泛的应用，如销售预测、个性化推荐等。协同过滤和基于内容的推荐是常用的技术。

### 5.制造业和物联网

物联网（IoT）在制造业中的应用越来越广泛，机器学习可用于处理和分析传感器数据，实现设备预测性维护和质量控制。

### 6.能源管理与环境保护

机器学习可以帮助优化能源管理，减少能源浪费，提高能源利用效率。通过分析大量的能源数据，识别优化的机会。

### 7.决策支持与智能分析

机器学习在决策支持系统中的应用也十分重要，可以帮助分析大量数据，辅助决策制定。基于数据的决策可以更加准确和有据可依。

### 8.图像识别与计算机视觉

图像识别和计算机视觉是另一个重要的机器学习应用领域，它使计算机能够理解和解释图像。深度学习模型如卷积神经网络（CNN）在图像分类、目标检测等任务中取得了突破性进展。

## 机器学习项目开发步骤

5个基本步骤用于执行机器学习任务：

1. **收集数据**：无论是来自excel，access，文本文件等的原始数据，这一步（收集过去的数据）构成了未来学习的基础。相关数据的种类，密度和数量越多，机器的学习前景就越好。
2. **准备数据**：任何分析过程都会依赖于使用的数据质量如何。人们需要花时间确定数据质量，然后采取措施解决诸如缺失的数据和异常值的处理等问题。探索性分析可能是一种详细研究数据细微差别的方法，从而使数据的质量迅速提高。
3. **练模型**：此步骤涉及以模型的形式选择适当的算法和数据表示。清理后的数据分为两部分 - 训练和测试（比例视前提确定）; 第一部分（训练数据）用于开发模型。第二部分（测试数据）用作参考依据。
4. **评估模型**：为了测试准确性，使用数据的第二部分（保持/测试数据）。此步骤根据结果确定算法选择的精度。检查模型准确性的更好测试是查看其在模型构建期间根本未使用的数据的性能。
5. **提高性能**：此步骤可能涉及选择完全不同的模型或引入更多变量来提高效率。这就是为什么需要花费大量时间进行数据收集和准备的原因。

无论是任何模型，这5个步骤都可用于构建技术，当我们讨论算法时，您将找到这五个步骤如何出现在每个模型中！

## 数据集

### 1.sklearn玩具数据集

- 定义

  数据量小，数据在sklearn库的本地，只要安装了sklearn，不用上网就可以获取

- 图示

  ![real_1](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/real_1.png)

### 2.sklearn现实世界数据集

- 定义

  数据量大，数据只能通过网络获取

- 图示

  ![toal_1](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/toal_1.png)

### 3.sklearn加载玩具数据集

#### 3.1 鸢尾花数据

- 语法

  ```python
  from sklearn.datasets import load_iris
  iris = load_iris()#鸢尾花数据,返回一个Bunch对象
  ```

- 特征

  - ​	花萼长 sepal length  
  - ​	花萼宽 sepal width 
  - ​	花瓣长 petal length  
  - ​	花瓣宽 petal width

- 分类

  - ​	0-Setosa山鸢尾    
  - ​	1-Versicolour变色鸢尾   
  - ​	2-Virginica维吉尼亚鸢尾

- 实例

  ```python
  import pandas as pd
  import numpy as np
  from sklearn.datasets import load_iris
  iris=load_iris()
  data=iris.data
  target=iris.target
  target=target.reshape(len(target),1)
  iris_con=np.hstack([data,target])
  col=iris.feature_names
  col.append('target')
  iris_show=pd.DataFrame(iris_con,columns=col)
  ```

  ![bird](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/bird.png)

#### 3.2 糖尿病数据

- 语法

  ```python
  from sklearn.datasets import  load_diabetes
  diabetes=load_diabetes()
  ```

- 特征

  - ‌**年龄（‌age）‌**‌
  - ‌**性别（‌sex）‌**‌
  - ‌**身体质量指数（‌bmi）‌**‌
  - ‌**平均血压（‌bp）‌**‌
  - ‌**六种血清的化验数据（‌s1~s6）‌**‌，‌包括T细胞（‌tc）‌、‌低密度脂蛋白（‌ldl）‌、‌高密度脂蛋白（‌hdl）‌、‌促甲状腺激素（‌tch）‌、‌拉莫三嗪（‌ltg）‌和血糖水平（‌glu）‌。‌

- 实例

  ```python
  from sklearn.datasets import  load_diabetes
  diabetes=load_diabetes()
  data=diabetes.data
  target=diabetes.target
  target=target.reshape(len(target),1)
  diabetes_con=np.hstack([data,target])
  col=diabetes.feature_names
  col.append('target')
  diabetes_show=pd.DataFrame(diabetes_con,columns=col)
  
  print(diabetes_show)
  ```

  ![tang](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/tang.png)



#### 3.3 数字数据集

- 语法

  ```python
  from sklearn.datasets import load_digits
  num=load_digits()
  ```

- 特征

  - 每个样本由64个特征组成，‌这些特征实际上是8x8像素图像中的每个像素的灰度值。‌灰度值通常是一个介于0到某个最大值（‌在这个数据集中是16）‌之间的整数，‌但在加载到sklearn中时，‌它们被转换为float64类型的值，‌并且通常会被归一化到[0, 1]范围内，。
  - 64个特征以线性方式排列，‌对应于8x8图像矩阵的展平版本。‌具体来说，‌第一个特征对应于图像左上角的像素，‌接下来的8个特征对应于第一行的其余像素，‌依此类推，‌直到遍历整个图像。‌

- 分类

  **含0-9共10种标签，‌各类样本均衡，‌特征为离散数值0-16之间**‌。‌

- 实例

  ```python
  from sklearn.datasets import load_digits
  num=load_digits()
  
  data=num.data
  target=num.target
  target=target.reshape(len(target),1)
  num_con=np.hstack([data,target])
  col=num.feature_names
  col.append('target')
  num_show=pd.DataFrame(num_con,columns=col)
  
  print(num_show)
  ```

  ![num](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/num.png)

#### 3.4 linnerud物理锻炼数据

- 语法

  ```python
  from sklearn.datasets import load_linnerud
  phy=load_linnerud()
  ```

- 特征

  Chins：引体向上

  Situps：仰卧起坐  

  Jumps：跳高  

- 目标参数

  Weight：体重  

  Waist：腰围  

  Pulse：脉搏

- 实例

  ```python
  from sklearn.datasets import load_linnerud
  phy=load_linnerud()
  
  data=phy.data
  target=phy.target
  phy_con=np.hstack([data,target])
  col=phy.feature_names
  col.append('Weight')
  col.append('Waist')
  col.append('Pulse')
  phy_show=pd.DataFrame(phy_con,columns=col)
  
  print(phy_show)
  ```

  ![phy](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/phy.png)

#### 3.5 葡萄酒数据集

- 语法

  ```python
  from sklearn.datasets import load_wine
  achlo=load_wine()
  ```

- 特征

  1.‌**酒精（‌alcohol）‌**‌：‌葡萄酒中的酒精含量。‌

  2.‌**苹果酸（‌malic_acid）‌**‌：‌葡萄酒中的苹果酸含量，‌苹果酸是一种有机酸，‌对葡萄酒的风味和口感有重要影响。‌

  3.‌**灰分（‌ash）‌**‌：‌葡萄酒中的灰分含量，‌灰分是葡萄酒中无机物质的总和，‌包括矿物质等。‌

  4.‌**灰的碱性（‌alcalinity_of_ash）‌**‌：‌灰分的碱性程度，‌反映了灰分中矿物质的种类和含量。‌

  5.‌**镁（‌magnesium）‌**‌：‌葡萄酒中的镁含量，‌镁是一种重要的矿物质，‌对葡萄酒的风味和稳定性有一定影响。‌

  6.‌**总酚（‌total_phenols）‌**‌：‌葡萄酒中的总酚含量，‌酚类物质是葡萄酒中的重要成分，‌对葡萄酒的颜色、‌风味和抗氧化性有贡献。‌

  7.‌**类黄酮（‌flavanoids）‌**‌：‌葡萄酒中的类黄酮含量，‌类黄酮是一类具有抗氧化性质的植物化学物质。‌

  8.‌**非黄烷类酚类（‌nonflavanoid_phenols）‌**‌：‌葡萄酒中的非黄烷类酚类物质含量，‌这些物质同样对葡萄酒的风味和抗氧化性有贡献。‌

  9.‌**花青素（‌proanthocyanins）‌**‌：‌葡萄酒中的花青素含量，‌花青素是一种强效的天然色素和抗氧化剂，‌对葡萄酒的颜色和稳定性有重要作用。‌

  10.‌**颜色强度（‌color_intensity）‌**‌：‌葡萄酒的颜色强度，‌反映了葡萄酒中色素的含量和分布。‌

  11.‌**色调（‌hue）‌**‌：‌葡萄酒的色调，‌即颜色的具体表现，‌如红葡萄酒可能呈现不同的红色调。‌

  12.‌**od280/od315稀释葡萄酒（‌od280/od315_of_diluted_wines）‌**‌：‌这是一个光学密度的比值，‌用于描述葡萄酒在特定波长下的吸收特性，‌与葡萄酒中的某些化学成分含量有关。‌

  13.‌**脯氨酸（‌proline）‌**‌：‌葡萄酒中的脯氨酸含量，‌脯氨酸是一种氨基酸，‌对葡萄酒的风味和口感有一定影响。‌

- 分类

  'class_0'

  'class_1'

  'class_2'

- 实例

  ```python
  from sklearn.datasets import load_wine
  achlo=load_wine()
  
  data=achlo.data
  target=achlo.target
  target=target.reshape(len(target),1)
  achlo_con=np.hstack([data,target])
  col=achlo.feature_names
  col.append('target')
  achlo_show=pd.DataFrame(achlo_con,columns=col)
  
  
  print(achlo_show)
  ```

  ![achol](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/achol.png)

#### 3.6 乳腺癌数据集

- 语法

  ```python
  from sklearn.datasets import load_breast_cancer
  cancer=load_breast_cancer()
  ```

- 特征

  1.‌**肿瘤的大小相关特征**‌：‌如半径、‌周长、‌面积等，‌这些特征直接反映了肿瘤的物理尺寸1。‌

  2.‌**肿瘤的形状和纹理特征**‌：‌如纹理（‌灰度值的标准偏差）‌、‌平滑度（‌半径的变化幅度）‌、‌密实度（‌周长的平方除以面积的商再减1）‌、‌凹度（‌凹陷部分轮廓的严重程度）‌、‌凹点（‌凹陷轮廓的数量）‌等，‌这些特征描述了肿瘤的表面形态和内部结构12。‌

  3.‌**其他生物学特征**‌：‌如对称性、‌分形维度等，‌这些特征提供了关于肿瘤生长方式和复杂性的额外信息

- 分类

  0表示良性肿瘤

  1表示恶性肿瘤

- 实例

  ```python
  from sklearn.datasets import load_breast_cancer
  cancer=load_breast_cancer()
  
  data=cancer.data
  target=cancer.target
  target=target.reshape(len(target),1)
  cancer_con=np.hstack([data,target])
  col=cancer.feature_names
  col=list(col)
  col.append('target')
  cancer_show=pd.DataFrame(cancer_con,columns=col)
  
  print(cancer_show)
  ```

  ![cancer](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/cancer.png)

### 4.sklearn获取现实世界数据集

#### 4.1获取20分类新闻数据

- 文件保存目录

  ```python
  """
  (1)所有现实世界数据，通过网络才能下载后，默认保存的目录可以使用下面api获取。实际上就是保存到家目录
  
  (2)下载时，有可能回为网络问题而出题，要“小心”的解决网络问题，不可言…..
  
  (3)第一次下载会保存的硬盘中，如果第二次下载，因为硬盘中已经保存有了，所以不会再次下载就直接加载成功了。
  
  """
  from sklearn import datasets
  ret=datasets.get_data_home()
  print(ret)
  #C:\Users\13167\scikit_learn_data
  ```

- 语法

  ```python
  sklearn.datasets.fetch_20newsgroups(data_home,subset)
  ```

- 参数

  data_home

  ```python
  =None
  这是默认值，下载的文件路径为 “C:/Users/ADMIN/scikit_learn_data/20news-bydate_py3.pkz”
  
  =自定义路径
  	例如 “./src”, 下载的文件路径为“./20news-bydate_py3.pkz”
  ```

  subset

  ```python
  “train”，只下载训练集
  “test”，只下载测试集
  “all”， 下载的数据包含了训练集和测试集
  ```

   return_X_y，决定着返回值的情况

  ```python
  当参数return_X_y值为False时， 函数返回Bunch对象,Bunch对象中有以下属性
      *data:特征数据集, 长度为18846的列表list, 每一个元素就是一篇新闻内容， 共有18846篇
      *target:目标数据集，长度为18846的数组ndarray, 第一个元素是一个整数，整数值为[0,20]
      *target_names:目标描述，长度为20的list
      *filenames：长度为18846的ndarray, 元素为字符串,代表新闻的数据位置的路径
      
  当参数return_X_y值为True时，函数返回值为元组，元组长度为2， 第一个元素值为特征数据集，第二个元素值为目标数据集
  ```

- 实例

  ```python
  from sklearn import datasets
  ret=sklearn.datasets.fetch_20newsgroups(data_home='./',subset='all')
  print(len(ret.data))
  print(ret.target.shape) #(18846,)
  print(ret.target_names) #20
  print(ret.filenames) #18846
  ```

  ![news](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/news.png)

#### 4.2加载加利福尼亚住房数据

- 语法

  ```python
  fetch_california_housing( *, data_home=None, download_if_missing=True, return_X_y=False, as_frame=False
  )
  ```

- 实例

  ```python
  from sklearn import datasets
  ret=datasets.fetch_california_housing(data_home='./',as_frame=True)
  print(ret.data)
  ```

  ![house](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/house.png)

### 5.本地csv数据创建和使用

#### 1.创建csv文件

方式1：打开计事本，写出如下数据，数据之间使用英文下的逗号, 保存文件后把后缀名改为csv

```python
milage,Liters,Consumtime,target
40920,8.326976,0.953952,3
14488,7.153469,1.673904,2
26052,1.441871,0.805124,1
75136,13.147394,0.428964,1
```

方式2：创建excel 文件,  填写数据，以csv为后缀保存文件

#### 2.pandas加载csv

```py
test=pd.read_csv('test1.csv')
print(test)
```

![csv](https://github.com/ljgit1316/Picture_resource/blob/main/Machine_Pic/csv.png)

### 6.数据集划分

#### 1.函数

```python
sklearn.model_selection.train_test_split(*arrays，**options)

"""
(1) *array 
	这里用于接收1到多个"列表、numpy数组、稀疏矩阵或padas中的DataFrame"。	
	
(2) **options， 重要的关键字参数有：
 	    test_size 值为0.0到1.0的小数，表示划分后测试集占的比例
        random_state 值为任意整数，表示随机种子，使用相同的随机种子对相同的数据集多次划分结果是相同的。否则多半不同
        
(3)返回值说明
	返回值为列表list, 列表长度与形参array接收到的参数数量相关联, 形参array接收到的是什么类型，list中对应被划分出来的两部分就是什么类型
"""
```

#### 2.列表数据集划分

```python
from sklearn.model_selection import train_test_split
data1 = [1,    2,    3,    4,    5]
data2 = ["1a", "2a","3a", "4a",  "5a"]
#随机种子都使用了相同的整数(11)，所以划分的划分的情况是相同的。
a, b = train_test_split(data1, test_size=0.1, random_state=11)
print(a, b)
#[5, 1, 4, 2] [3]
a, b = train_test_split(data2, test_size=0.1, random_state=11)
print(a, b)
#['5a', '1a', '4a', '2a'] ['3a']
a, b, c, d  = train_test_split(data1, data2,  test_size=0.1, random_state=11)
print(a,b,c,d)
#[5, 1, 4, 2] [3] ['5a', '1a', '4a', '2a'] ['3a']
```

#### 3.ndarray数据集划分

```python
#划分前和划分后的数据类型是相同的
data1 = [1,    2,    3,    4,    5]
data2 = np.array(["1a", "2a","3a", "4a",  "5a"]) 
a, b, c, d  = train_test_split(data1, data2,  test_size=0.4, random_state=22)
print(a, b, c, d)  
#[4, 1, 5] [2, 3] ['4a' '1a' '5a'] ['2a' '3a']
print(type(a), type(b), type(c), type(d)) 
#<class 'list'> <class 'list'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>
```

#### 4.二维数组数据集划分

```python
from sklearn.model_selection import train_test_split
import numpy as np
data1 = np.arange(1, 16, 1)
data1.shape=(5,3)
print(data1)
a, b = train_test_split(data1,  test_size=0.4, random_state=22)
print(a)
print(b)

"""
[[ 1  2  3]
 [ 4  5  6]
 [ 7  8  9]
 [10 11 12]
 [13 14 15]]
 
 [[10 11 12]
 [ 1  2  3]
 [13 14 15]]

 [[4 5 6]
 [7 8 9]]

"""
```

#### 5.DataFrame数据集划分

```python
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
#可以划分DataFrame, 划分后的两部分还是DataFrame
data1 = np.arange(1, 16, 1)
data1.shape=(5,3)
data1 = pd.DataFrame(data1, index=[1,2,3,4,5], columns=["one","two","three"])
print(data1)

a, b = train_test_split(data1,  test_size=0.4, random_state=22)
print(a)
print(b)

"""
 one  two  three
1    1    2      3
2    4    5      6
3    7    8      9
4   10   11     12
5   13   14     15

    one  two  three
4   10   11     12
1    1    2      3
5   13   14     15

    one  two  three
2    4    5      6
3    7    8      9

"""
```

#### 6.字典数据集划分

```python
"""
可以划分非稀疏矩阵

用于将字典列表转换为特征向量。这个转换器主要用于处理类别数据和数值数据的混合型数据集

1.对于类别特征`DictVectorizer` 会为每个不同的类别创建一个新的二进制特征，如果原始数据中的某个样本具有该类别，则对应的二进制特征值为1，否则为0。

2.对于数值特征保持不变，直接作为特征的一部分
"""
```

```python
from sklearn.feature_extraction import DictVectorizer
data = [{'city':'成都', 'age':30, 'temperature':20}, 
        {'city':'重庆','age':33, 'temperature':60}, 
        {'city':'北京', 'age':42, 'temperature':80},
        {'city':'上海', 'age':22, 'temperature':70},
        {'city':'成都', 'age':72, 'temperature':40},
       ]
transfer = DictVectorizer(sparse=True)
data_new = transfer.fit_transform(data)
print("data_new:\n", data_new)
x = data_new.toarray()
print(type(x))
print(x)
"""
(0,0)是矩阵的行列下标  30是值
data_new:
  (0, 0)	30.0
  (0, 3)	1.0
  (0, 5)	20.0
  (1, 0)	33.0
  (1, 4)	1.0
  (1, 5)	60.0
  (2, 0)	42.0
  (2, 2)	1.0
  (2, 5)	80.0
  (3, 0)	22.0
  (3, 1)	1.0
  (3, 5)	70.0
  (4, 0)	72.0
  (4, 3)	1.0
  (4, 5)	40.0
<class 'numpy.ndarray'>
# 第一行中:30表示age的值  0表示上海 0表示北京 1表示成都 0表示重庆 20表示temperature
[[30.  0.  0.  1.  0. 20.]
 [33.  0.  0.  0.  1. 60.]
 [42.  0.  1.  0.  0. 80.]
 [22.  1.  0.  0.  0. 70.]
 [72.  0.  0.  1.  0. 40.]]

"""
```

```python
a, b = train_test_split(data_new,  test_size=0.4, random_state=22)
print(a)
print("\n", b)

"""
  (0, 0)	22.0
  (0, 1)	1.0
  (0, 5)	70.0
  (1, 0)	30.0
  (1, 3)	1.0
  (1, 5)	20.0
  (2, 0)	72.0
  (2, 3)	1.0
  (2, 5)	40.0

  (0, 0)	33.0
  (0, 4)	1.0
  (0, 5)	60.0
  (1, 0)	42.0
  (1, 2)	1.0
  (1, 5)	80.0


"""
```

```python
#data_new.toarray()是ndarray
a, b = train_test_split(data_new.toarray(),  test_size=0.4, random_state=22)
print(a)
print("\n", b)
"""
[[22.  1.  0.  0.  0. 70.]
 [30.  0.  0.  1.  0. 20.]
 [72.  0.  0.  1.  0. 40.]]

 [[33.  0.  0.  0.  1. 60.]
 [42.  0.  1.  0.  0. 80.]]

"""
```

#### 7.鸢尾花数据集划分

```python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
iris = load_iris()
list = train_test_split(iris.data,iris.target,  test_size=0.2, random_state=22)
#x_train训练特征数据集,x_test测试特征数据集, y_train训练目标数据集,y_test测试目标数据集,
x_train, x_test, y_train, y_test = list   
#(120, 4) (30, 4) (120,) (30,)
print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)
```

#### 8.现实世界数据集划分

```python
from sklearn.datasets import fetch_20newsgroups
from sklearn.model_selection import train_test_split
import numpy as np
news = fetch_20newsgroups(data_home='./', subset='all')
list = train_test_split(news.data, news.target,test_size=0.2, random_state=22)
# """
# 返回值是一个list:其中有4个值，分别为训练集特征、测试集特征、训练集目标、测试集目标
x_train, x_test, y_train, y_test = list
# 15076 3770 (15076,) (3770,)
print(len(x_train), len(x_test), y_train.shape, y_test.shape) 
```

```python
#“加载加利福尼亚住房数据集”,并进行数据集划分
from sklearn import datasets
ret=datasets.fetch_california_housing(data_home='./',as_frame=True)
list=train_test_split(ret.data,ret.target,test_size=0.2,random_state=22)
x_train,x_target,y_train,y_target=list
print(x_train,x_target)
print(y_train,y_target)

```
